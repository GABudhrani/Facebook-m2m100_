{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1672,"status":"ok","timestamp":1659291183693,"user":{"displayName":"Girish Budhrani","userId":"13607137338318636456"},"user_tz":-330},"id":"0T72qkAvF0UL","outputId":"1e04577a-1fc9-4f2e-c48a-a8bbbe250fe6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sun Jul 31 18:13:02 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   40C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3546,"status":"ok","timestamp":1659022512632,"user":{"displayName":"Girish Budhrani","userId":"13607137338318636456"},"user_tz":-330},"id":"Gy6yOHQvclI4","outputId":"59e5b1a5-d157-4a1c-fdc2-139853ce299c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.21.0)\n","Requirement already satisfied: huggingface-hub\u003c1.0,\u003e=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: tokenizers!=0.11.3,\u003c0.13,\u003e=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.1.0-\u003etransformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging\u003e=20.0-\u003etransformers) (3.0.9)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003etransformers) (3.8.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (1.24.3)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (2.10)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (3.0.4)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (2022.6.15)\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":383},"executionInfo":{"elapsed":5,"status":"error","timestamp":1659022515706,"user":{"displayName":"Girish Budhrani","userId":"13607137338318636456"},"user_tz":-330},"id":"_ULh4Ak5chru","outputId":"2c11fa6e-2aa0-494f-b6c0-6cc1e286e6f9"},"outputs":[{"ename":"ImportError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-12-888f7a16d7e6\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModelForSeq2SeqLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"facebook/nllb-200-distilled-600M\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSeq2SeqLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"facebook/nllb-200-distilled-600M\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'AutoModelForSeq2SeqLM' from 'transformers' (unknown location)","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}],"source":["from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n","model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n","\n","article = \"UN Chief says there is no military solution in Syria\"\n","inputs = tokenizer(article, return_tensors=\"pt\")\n","\n","translated_tokens = model.generate(\n","    **inputs, forced_bos_token_id=tokenizer.lang_code_to_id[\"fra_Latn\"], max_length=30\n",")\n","tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25189,"status":"ok","timestamp":1659291208877,"user":{"displayName":"Girish Budhrani","userId":"13607137338318636456"},"user_tz":-330},"id":"KBNTPdoNF3zo","outputId":"8556d860-d33e-44bb-a5ca-66b111a41102"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1659291208878,"user":{"displayName":"Girish Budhrani","userId":"13607137338318636456"},"user_tz":-330},"id":"e4E6SxanF7Io","outputId":"21952baa-c023-49d0-d569-18217bea9f56"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/nmt google\n"]}],"source":["%cd /content/drive/MyDrive/nmt google"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"86f1c2e5"},"outputs":[],"source":["import csv\n","import json\n","\n","def make_json(csvFilePath, jsonFilePath):\n","\n","    data = {}\n","    final_list = []\n","    with open(csvFilePath) as csvf:\n","        csvReader = csv.DictReader(csvf)\n","        for rows in csvReader:\n","            dict1 = {}\n","            dict1[\"hi\"] = rows['Hindi']\n","            dict1[\"en\"] = rows[\"Hinglish\"]\n","            final_list.append(dict1)\n","    data[\"data\"] = final_list\n","    with open(jsonFilePath, 'w', encoding='utf-8') as jsonf:\n","        jsonf.write(json.dumps(data, indent=4, ensure_ascii=False))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1020,"status":"ok","timestamp":1658563617907,"user":{"displayName":"Girish Budhrani","userId":"13607137338318636456"},"user_tz":-330},"id":"337e5ff1","outputId":"f11ae6dc-fda3-4475-e6fb-09390c6017a2"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'hi': '‡§ó‡•à‡§≤‡§∞‡•Ä ‡§ë‡§´‡§ø‡§∏ ‡§∏‡•â‡§´‡•ç‡§ü‡§µ‡•á‡§Ø‡§∞ ‡§á‡§∏ ‡§â‡§™‡§ï‡§∞‡§£ ‡§™‡§∞ ‡§Æ‡•à‡§®‡•Å‡§Ö‡§≤‡•Ä ‡§ë‡§´‡§ø‡§∏ ‡§ï‡§æ ‡§∏‡•â‡§´‡•ç‡§ü‡§µ‡•á‡§Ø‡§∞ 1 ‡§∏‡§æ‡§≤ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§¶‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à.', 'en': 'milega office subscription is device par microsoft office ka subscription 1 saal ke liye diya gya hain'}\n"]}],"source":["csvFilePath = r'hi-hg/train.csv'\n","jsonFilePath = r'hi-hg/train.json'\n","make_json(csvFilePath, jsonFilePath)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VMXw2zfewPwW"},"outputs":[],"source":["import pandas as pd\n","src=\"valid.hi\"\n","trg=\"valid.en\"\n","df = pd.read_csv(\"hi-hg/\"+src, delimiter=\"\\n\",names=[\"Hindi\"])\n","df2 = pd.read_csv(\"hi-hg/\"+trg, delimiter=\"\\n\",names=[\"Hinglish\"])\n","df = df.join(df2)\n","df.to_csv(\"hi-hg/valid.csv\")"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":69621,"status":"ok","timestamp":1659291288088,"user":{"displayName":"Girish Budhrani","userId":"13607137338318636456"},"user_tz":-330},"id":"2faa8b34","outputId":"16fb9c37-5978-4dc7-defa-9e8d00023f10"},"outputs":[{"name":"stdout","output_type":"stream","text":["  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.6 MB 5.2 MB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 101 kB 11.3 MB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 596 kB 59.3 MB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 298 kB 5.1 MB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 116 kB 67.4 MB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.2 MB 60.1 MB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 123 kB 70.5 MB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 65 kB 3.5 MB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 141 kB 67.0 MB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 212 kB 65.5 MB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.4 MB 45.5 MB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.3 MB 37.6 MB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 357 kB 62.5 MB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 138 kB 62.3 MB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 92 kB 107 kB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50 kB 5.0 MB/s \n","\u001b[?25h"]}],"source":["# !git clone https://github.com/rumeshmadhusanka/mt5-simplification.git\n","# !git clone https://github.com/huggingface/transformers.git\n","! cd transformers \u0026\u0026 \\\n","pip install --editable ./ -q\n","!pip install gdown datasets==1.16.1 sacrebleu sentencepiece protobuf accelerate py7zr -q"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15726,"status":"ok","timestamp":1659291303805,"user":{"displayName":"Girish Budhrani","userId":"13607137338318636456"},"user_tz":-330},"id":"d7ffaca5","outputId":"15629804-5001-490d-812b-39447e0586ed"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.5 MB 5.1 MB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 76 kB 4.6 MB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20.1 MB 952 kB/s \n","\u001b[?25h  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","xarray-einstats 0.2.2 requires numpy\u003e=1.21, but you have numpy 1.18.5 which is incompatible.\n","tensorflow 2.8.2+zzzcolab20220719082949 requires numpy\u003e=1.20, but you have numpy 1.18.5 which is incompatible.\n","tables 3.7.0 requires numpy\u003e=1.19.0, but you have numpy 1.18.5 which is incompatible.\n","jaxlib 0.3.14+cuda11.cudnn805 requires numpy\u003e=1.19, but you have numpy 1.18.5 which is incompatible.\n","jax 0.3.14 requires numpy\u003e=1.19, but you have numpy 1.18.5 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","cmdstanpy 1.0.4 requires numpy\u003e=1.21, but you have numpy 1.18.5 which is incompatible.\n","albumentations 0.1.12 requires imgaug\u003c0.2.7,\u003e=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n"]}],"source":["import transformers\n","!pip install -r mt5-simplification/requirements.txt -q"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":536},"executionInfo":{"elapsed":7729,"status":"ok","timestamp":1659291311527,"user":{"displayName":"Girish Budhrani","userId":"13607137338318636456"},"user_tz":-330},"id":"xhCo0BuPG6sD","outputId":"1b931114-8024-48af-a8b8-049ba214dc6e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.21.0-py3-none-any.whl (4.7 MB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.7 MB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tokenizers!=0.11.3,\u003c0.13,\u003e=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: huggingface-hub\u003c1.0,\u003e=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.1.0-\u003etransformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging\u003e=20.0-\u003etransformers) (3.0.9)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003etransformers) (3.8.1)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (1.24.3)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (2022.6.15)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (3.0.4)\n","Installing collected packages: transformers\n","Successfully installed transformers-4.21.0\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["transformers"]}}},"metadata":{},"output_type":"display_data"}],"source":["!pip install transformers\n","import transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":63167,"status":"ok","timestamp":1659019598500,"user":{"displayName":"Girish Budhrani","userId":"13607137338318636456"},"user_tz":-330},"id":"slQ7Ar0fJwGv","outputId":"dea0e106-0c23-48a1-f0b4-64d2e32b3221"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting deepspeed\n","  Downloading deepspeed-0.6.7.tar.gz (586 kB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 586 kB 14.4 MB/s \n","\u001b[?25hCollecting hjson\n","  Downloading hjson-3.0.2-py3-none-any.whl (54 kB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 54 kB 2.9 MB/s \n","\u001b[?25hCollecting ninja\n","  Downloading ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 108 kB 81.4 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepspeed) (1.18.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from deepspeed) (21.3)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from deepspeed) (5.4.8)\n","Collecting py-cpuinfo\n","  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99 kB 9.5 MB/s \n","\u001b[?25hRequirement already satisfied: pydantic in /usr/local/lib/python3.7/dist-packages (from deepspeed) (1.9.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from deepspeed) (1.12.0+cu113)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from deepspeed) (4.62.3)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-\u003edeepspeed) (3.0.9)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pydantic-\u003edeepspeed) (4.1.1)\n","Building wheels for collected packages: deepspeed, py-cpuinfo\n","  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for deepspeed: filename=deepspeed-0.6.7-py3-none-any.whl size=586848 sha256=0a5888c7f69416bafa18e779038a57186310cf43be319539dc3ffc9f1fee5f9e\n","  Stored in directory: /root/.cache/pip/wheels/5d/3e/fb/abb0ffc8751f28c306d8b63d23f62b51e1d92127a6f1b55408\n","  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=f3580f26498f7e9c6c555a428ff7fc51c139d03d2ffe9e7e5a6445e270274ec2\n","  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n","Successfully built deepspeed py-cpuinfo\n","Installing collected packages: py-cpuinfo, ninja, hjson, deepspeed\n","Successfully installed deepspeed-0.6.7 hjson-3.0.2 ninja-1.10.2.3 py-cpuinfo-8.0.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mpi4py\n","  Downloading mpi4py-3.1.3.tar.gz (2.5 MB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.5 MB 15.5 MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: mpi4py\n","  Building wheel for mpi4py (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mpi4py: filename=mpi4py-3.1.3-cp37-cp37m-linux_x86_64.whl size=2185266 sha256=0ccd4936ac0230278bce298ffb2ff69dcbe7a266d9abfddf117d7fd77ee7528f\n","  Stored in directory: /root/.cache/pip/wheels/7a/07/14/6a0c63fa2c6e473c6edc40985b7d89f05c61ff25ee7f0ad9ac\n","Successfully built mpi4py\n","Installing collected packages: mpi4py\n","Successfully installed mpi4py-3.1.3\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","\u001b[31mERROR: Could not find a version that satisfies the requirement cuda (from versions: none)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for cuda\u001b[0m\n"]}],"source":["# !pip install deepspeed\n","# !pip install mpi4py"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"7bd70698"},"outputs":[{"name":"stdout","output_type":"stream","text":["07/31/2022 18:19:20 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n","07/31/2022 18:19:20 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n","_n_gpu=1,\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_pin_memory=True,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","do_eval=True,\n","do_predict=False,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_steps=None,\n","evaluation_strategy=no,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=True,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","generation_max_length=None,\n","generation_num_beams=None,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_model_id=None,\n","hub_private_repo=False,\n","hub_strategy=every_save,\n","hub_token=\u003cHUB_TOKEN\u003e,\n","ignore_data_skip=False,\n","include_inputs_for_metrics=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=3e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=-1,\n","log_level=10,\n","log_level_replica=-1,\n","log_on_each_node=True,\n","logging_dir=translation-hg-hi/runs/Jul31_18-19-20_71ef99b3243a,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=steps,\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=10000,\n","metric_for_best_model=None,\n","mp_parameters=,\n","no_cuda=False,\n","num_train_epochs=3.0,\n","optim=adamw_hf,\n","output_dir=translation-hg-hi,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=4,\n","per_device_train_batch_size=4,\n","predict_with_generate=True,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=\u003cPUSH_TO_HUB_TOKEN\u003e,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard'],\n","resume_from_checkpoint=None,\n","run_name=translation-hg-hi,\n","save_on_each_node=False,\n","save_steps=500,\n","save_strategy=epoch,\n","save_total_limit=1,\n","seed=42,\n","sharded_ddp=[],\n","skip_memory_metrics=True,\n","sortish_sampler=False,\n","tf32=None,\n","torchdynamo=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","warmup_ratio=0.0,\n","warmup_steps=500,\n","weight_decay=3e-07,\n","xpu_backend=None,\n",")\n","07/31/2022 18:19:20 - WARNING - datasets.builder - Using custom data configuration default-e2b4f847be942fab\n","07/31/2022 18:19:20 - DEBUG - datasets.utils.filelock - Attempting to acquire lock 140174904845968 on /root/.cache/huggingface/datasets/_root_.cache_huggingface_datasets_json_default-e2b4f847be942fab_0.0.0_c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426.lock\n","07/31/2022 18:19:20 - DEBUG - datasets.utils.filelock - Lock 140174904845968 acquired on /root/.cache/huggingface/datasets/_root_.cache_huggingface_datasets_json_default-e2b4f847be942fab_0.0.0_c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426.lock\n","07/31/2022 18:19:20 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n","07/31/2022 18:19:20 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-e2b4f847be942fab/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426\n","07/31/2022 18:19:20 - DEBUG - datasets.utils.filelock - Attempting to release lock 140174904845968 on /root/.cache/huggingface/datasets/_root_.cache_huggingface_datasets_json_default-e2b4f847be942fab_0.0.0_c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426.lock\n","07/31/2022 18:19:20 - DEBUG - datasets.utils.filelock - Lock 140174904845968 released on /root/.cache/huggingface/datasets/_root_.cache_huggingface_datasets_json_default-e2b4f847be942fab_0.0.0_c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426.lock\n","07/31/2022 18:19:20 - DEBUG - datasets.utils.filelock - Attempting to acquire lock 140174904847632 on /root/.cache/huggingface/datasets/_root_.cache_huggingface_datasets_json_default-e2b4f847be942fab_0.0.0_c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426.lock\n","07/31/2022 18:19:20 - DEBUG - datasets.utils.filelock - Lock 140174904847632 acquired on /root/.cache/huggingface/datasets/_root_.cache_huggingface_datasets_json_default-e2b4f847be942fab_0.0.0_c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426.lock\n","07/31/2022 18:19:20 - WARNING - datasets.builder - Reusing dataset json (/root/.cache/huggingface/datasets/json/default-e2b4f847be942fab/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426)\n","07/31/2022 18:19:20 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-e2b4f847be942fab/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426\n","07/31/2022 18:19:20 - DEBUG - datasets.utils.filelock - Attempting to release lock 140174904847632 on /root/.cache/huggingface/datasets/_root_.cache_huggingface_datasets_json_default-e2b4f847be942fab_0.0.0_c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426.lock\n","07/31/2022 18:19:20 - DEBUG - datasets.utils.filelock - Lock 140174904847632 released on /root/.cache/huggingface/datasets/_root_.cache_huggingface_datasets_json_default-e2b4f847be942fab_0.0.0_c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426.lock\n","07/31/2022 18:19:20 - DEBUG - datasets.builder - Constructing Dataset for split train, validation, from /root/.cache/huggingface/datasets/json/default-e2b4f847be942fab/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426\n","100% 2/2 [00:00\u003c00:00, 722.72it/s]\n","[INFO|hub.py:600] 2022-07-31 18:19:20,987 \u003e\u003e https://huggingface.co/facebook/m2m100-12B-last-ckpt/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp15eg68ou\n","Downloading config.json: 100% 795/795 [00:00\u003c00:00, 1.33MB/s]\n","[INFO|hub.py:613] 2022-07-31 18:19:21,085 \u003e\u003e storing https://huggingface.co/facebook/m2m100-12B-last-ckpt/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/a8c4d7a92443d5679fc0abc6f790a90790824465a3fdb32d254e85d7061bf077.42ecd7383aa876182293f666847f978f9b44fec4999fe87e80b4671e5002d8d4\n","[INFO|hub.py:621] 2022-07-31 18:19:21,085 \u003e\u003e creating metadata file for /root/.cache/huggingface/transformers/a8c4d7a92443d5679fc0abc6f790a90790824465a3fdb32d254e85d7061bf077.42ecd7383aa876182293f666847f978f9b44fec4999fe87e80b4671e5002d8d4\n","[INFO|configuration_utils.py:674] 2022-07-31 18:19:21,086 \u003e\u003e loading configuration file https://huggingface.co/facebook/m2m100-12B-last-ckpt/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a8c4d7a92443d5679fc0abc6f790a90790824465a3fdb32d254e85d7061bf077.42ecd7383aa876182293f666847f978f9b44fec4999fe87e80b4671e5002d8d4\n","[INFO|configuration_utils.py:723] 2022-07-31 18:19:21,089 \u003e\u003e Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100-12B-last-ckpt\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 4096,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 16384,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 24,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 16384,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 24,\n","  \"eos_token_id\": 2,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.21.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|hub.py:600] 2022-07-31 18:19:21,187 \u003e\u003e https://huggingface.co/facebook/m2m100-12B-last-ckpt/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpl0p9rqbv\n","Downloading tokenizer_config.json: 100% 1.41k/1.41k [00:00\u003c00:00, 1.96MB/s]\n","[INFO|hub.py:613] 2022-07-31 18:19:21,284 \u003e\u003e storing https://huggingface.co/facebook/m2m100-12B-last-ckpt/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/201a14703d73bb1615f38cc7061ea9b69a7b55e2392f5dedfaa3ef71453abf8e.67c564ce0acc42179250550d43ac1a68fa0341d4a2851e1d86542a0b57b3b71d\n","[INFO|hub.py:621] 2022-07-31 18:19:21,284 \u003e\u003e creating metadata file for /root/.cache/huggingface/transformers/201a14703d73bb1615f38cc7061ea9b69a7b55e2392f5dedfaa3ef71453abf8e.67c564ce0acc42179250550d43ac1a68fa0341d4a2851e1d86542a0b57b3b71d\n","[INFO|hub.py:600] 2022-07-31 18:19:21,400 \u003e\u003e https://huggingface.co/facebook/m2m100-12B-last-ckpt/resolve/main/vocab.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpp6qssme1\n","Downloading vocab.json: 100% 3.54M/3.54M [00:00\u003c00:00, 20.6MB/s]\n","[INFO|hub.py:613] 2022-07-31 18:19:21,846 \u003e\u003e storing https://huggingface.co/facebook/m2m100-12B-last-ckpt/resolve/main/vocab.json in cache at /root/.cache/huggingface/transformers/b6529a668e021f8eee38b984a555c41666ca910d31f64dee8031f9f91cd7ff88.469e7a402998e9590fd24cd8fb7df9c9686ecb7fa85274136b18e4231be29d39\n","[INFO|hub.py:621] 2022-07-31 18:19:21,847 \u003e\u003e creating metadata file for /root/.cache/huggingface/transformers/b6529a668e021f8eee38b984a555c41666ca910d31f64dee8031f9f91cd7ff88.469e7a402998e9590fd24cd8fb7df9c9686ecb7fa85274136b18e4231be29d39\n","[INFO|hub.py:600] 2022-07-31 18:19:21,944 \u003e\u003e https://huggingface.co/facebook/m2m100-12B-last-ckpt/resolve/main/sentencepiece.bpe.model not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpd2g4n8jw\n","Downloading sentencepiece.bpe.model: 100% 2.31M/2.31M [00:00\u003c00:00, 13.4MB/s]\n","[INFO|hub.py:613] 2022-07-31 18:19:22,551 \u003e\u003e storing https://huggingface.co/facebook/m2m100-12B-last-ckpt/resolve/main/sentencepiece.bpe.model in cache at /root/.cache/huggingface/transformers/f98389fd67811db8393a801ba25bb25102b03bd52c827af6b68a65b77b62272c.f4e5901d4bbb508f3cc5d9b07c765fad081143b0cf6afc5b32bc1a0f3363aec6\n","[INFO|hub.py:621] 2022-07-31 18:19:22,552 \u003e\u003e creating metadata file for /root/.cache/huggingface/transformers/f98389fd67811db8393a801ba25bb25102b03bd52c827af6b68a65b77b62272c.f4e5901d4bbb508f3cc5d9b07c765fad081143b0cf6afc5b32bc1a0f3363aec6\n","[DEBUG|tokenization_utils_base.py:1775] 2022-07-31 18:19:22,756 \u003e\u003e facebook/m2m100-12B-last-ckpt does not contain a file named https://huggingface.co/facebook/m2m100-12B-last-ckpt/resolve/main/added_tokens.json.\n","[INFO|hub.py:600] 2022-07-31 18:19:22,854 \u003e\u003e https://huggingface.co/facebook/m2m100-12B-last-ckpt/resolve/main/special_tokens_map.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpb14hmztc\n","Downloading special_tokens_map.json: 100% 1.11k/1.11k [00:00\u003c00:00, 1.83MB/s]\n","[INFO|hub.py:613] 2022-07-31 18:19:22,951 \u003e\u003e storing https://huggingface.co/facebook/m2m100-12B-last-ckpt/resolve/main/special_tokens_map.json in cache at /root/.cache/huggingface/transformers/031f08cc98b76a212032a2ebfe44e327cce8083aaf9803be1c9033696a9185f0.7e80b600cf19d2df58762f762130440df8dc1efa138330ca0e49ae816ae3cb56\n","[INFO|hub.py:621] 2022-07-31 18:19:22,952 \u003e\u003e creating metadata file for /root/.cache/huggingface/transformers/031f08cc98b76a212032a2ebfe44e327cce8083aaf9803be1c9033696a9185f0.7e80b600cf19d2df58762f762130440df8dc1efa138330ca0e49ae816ae3cb56\n","[INFO|tokenization_utils_base.py:1803] 2022-07-31 18:19:22,952 \u003e\u003e loading file https://huggingface.co/facebook/m2m100-12B-last-ckpt/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/b6529a668e021f8eee38b984a555c41666ca910d31f64dee8031f9f91cd7ff88.469e7a402998e9590fd24cd8fb7df9c9686ecb7fa85274136b18e4231be29d39\n","[INFO|tokenization_utils_base.py:1803] 2022-07-31 18:19:22,952 \u003e\u003e loading file https://huggingface.co/facebook/m2m100-12B-last-ckpt/resolve/main/sentencepiece.bpe.model from cache at /root/.cache/huggingface/transformers/f98389fd67811db8393a801ba25bb25102b03bd52c827af6b68a65b77b62272c.f4e5901d4bbb508f3cc5d9b07c765fad081143b0cf6afc5b32bc1a0f3363aec6\n","[INFO|tokenization_utils_base.py:1803] 2022-07-31 18:19:22,952 \u003e\u003e loading file https://huggingface.co/facebook/m2m100-12B-last-ckpt/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/201a14703d73bb1615f38cc7061ea9b69a7b55e2392f5dedfaa3ef71453abf8e.67c564ce0acc42179250550d43ac1a68fa0341d4a2851e1d86542a0b57b3b71d\n","[INFO|tokenization_utils_base.py:1803] 2022-07-31 18:19:22,952 \u003e\u003e loading file https://huggingface.co/facebook/m2m100-12B-last-ckpt/resolve/main/added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:1803] 2022-07-31 18:19:22,952 \u003e\u003e loading file https://huggingface.co/facebook/m2m100-12B-last-ckpt/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/031f08cc98b76a212032a2ebfe44e327cce8083aaf9803be1c9033696a9185f0.7e80b600cf19d2df58762f762130440df8dc1efa138330ca0e49ae816ae3cb56\n","[INFO|hub.py:600] 2022-07-31 18:19:23,240 \u003e\u003e https://huggingface.co/facebook/m2m100-12B-last-ckpt/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpz6n9ocd8\n","Downloading pytorch_model.bin: 100% 44.0G/44.0G [15:25\u003c00:00, 51.0MB/s]\n","[INFO|hub.py:613] 2022-07-31 18:34:48,934 \u003e\u003e storing https://huggingface.co/facebook/m2m100-12B-last-ckpt/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/f2a55b4b856251cafd4782a681baa86e569129d848e470e962aea096997039c1.4e9ac1aeb284ec0e9e067a638ca67009f41ff515d457fe32e803a77d76a083de\n","[INFO|hub.py:621] 2022-07-31 18:34:48,935 \u003e\u003e creating metadata file for /root/.cache/huggingface/transformers/f2a55b4b856251cafd4782a681baa86e569129d848e470e962aea096997039c1.4e9ac1aeb284ec0e9e067a638ca67009f41ff515d457fe32e803a77d76a083de\n","[INFO|modeling_utils.py:2034] 2022-07-31 18:34:48,935 \u003e\u003e loading weights file https://huggingface.co/facebook/m2m100-12B-last-ckpt/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/f2a55b4b856251cafd4782a681baa86e569129d848e470e962aea096997039c1.4e9ac1aeb284ec0e9e067a638ca67009f41ff515d457fe32e803a77d76a083de\n","tcmalloc: large alloc 2098987008 bytes == 0xd52e000 @  0x7f7e1e083b6b 0x7f7e1e0a3379 0x7f7d0b15bd57 0x7f7d0b149bc3 0x7f7d36d0e8c0 0x7f7d5cff3c14 0x7f7d5cc7dd61 0x593784 0x594731 0x548cc1 0x51566f 0x549e0e 0x593fce 0x5118f8 0x549e0e 0x4bcb19 0x59582d 0x595b69 0x62026d 0x55de15 0x59af67 0x515655 0x549e0e 0x4bca8a 0x5134a6 0x549576 0x593fce 0x548ae9 0x5127f1 0x593dd7 0x5118f8\n","tcmalloc: large alloc 2098987008 bytes == 0x7f7360d00000 @  0x7f7e1e083b6b 0x7f7e1e0a3379 0x7f7d0b15bd57 0x7f7d0b149bc3 0x7f7d3503f39f 0x7f7d3503fd10 0x7f7d3503fd64 0x7f7d35550fff 0x7f7d35dc189b 0x7f7d35b0d223 0x7f7d35d9c9bf 0x7f7d35b4abf7 0x7f7d5ce4d355 0x517553 0x549e0e 0x4bcb19 0x532b86 0x594a96 0x548cc1 0x51566f 0x549e0e 0x4bcb19 0x532b86 0x594a96 0x515600 0x549e0e 0x4bcb19 0x532b86 0x53786a 0x595ef6 0x5134a6\n","^C\n"]}],"source":["#for translation\n","model=\"facebook/m2m100-12B-last-ckpt\"\n","!python mt5-simplification/finetune.py \\\n","    --model_name_or_path $model \\\n","    --do_train \\\n","    --do_eval \\\n","    --source_lang hi \\\n","    --fp16_full_eval \\\n","    --target_lang en \\\n","    --source_prefix \"hi-en: \" \\\n","    --weight_decay 3e-7\\\n","    --train_file hi-hg/train.json \\\n","    --validation_file hi-hg/valid.json \\\n","    --output_dir mt5-simplification \\\n","    --per_device_train_batch_size=4 \\\n","    --per_device_eval_batch_size=4 \\\n","    --save_total_limit=1 \\\n","    --adam_epsilon=1e-8 \\\n","    --learning_rate=3e-5 \\\n","    --save_strategy=epoch \\\n","    --max_steps=10000 \\\n","    --warmup_steps=500 \\\n","    --overwrite_output_dir \\\n","    --log_level debug \\\n","    --output_dir translation-hg-hi \\\n","    --predict_with_generate \\"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":87580,"status":"ok","timestamp":1659182669756,"user":{"displayName":"Girish Budhrani","userId":"13607137338318636456"},"user_tz":-330},"id":"516934c0","outputId":"6789ddcc-0b94-4fe9-bc9b-883f802e17df"},"outputs":[{"name":"stdout","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/training_args.py:1080: FutureWarning: `--adafactor` is deprecated and will be removed in version 5 of ü§ó Transformers. Use `--optim adafactor` instead\n","  FutureWarning,\n","07/30/2022 12:03:07 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n","07/30/2022 12:03:07 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n","_n_gpu=1,\n","adafactor=True,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-06,\n","auto_find_batch_size=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_pin_memory=True,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","do_eval=True,\n","do_predict=False,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_steps=None,\n","evaluation_strategy=no,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","generation_max_length=None,\n","generation_num_beams=None,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_model_id=None,\n","hub_private_repo=False,\n","hub_strategy=every_save,\n","hub_token=\u003cHUB_TOKEN\u003e,\n","ignore_data_skip=False,\n","include_inputs_for_metrics=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=3e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=-1,\n","log_level=10,\n","log_level_replica=-1,\n","log_on_each_node=True,\n","logging_dir=translation-hi-hg_finetune/runs/Jul30_12-03-07_f60b3184cc30,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=steps,\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=10000,\n","metric_for_best_model=None,\n","mp_parameters=,\n","no_cuda=False,\n","num_train_epochs=3.0,\n","optim=adafactor,\n","output_dir=translation-hi-hg_finetune,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=4,\n","per_device_train_batch_size=4,\n","predict_with_generate=True,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=\u003cPUSH_TO_HUB_TOKEN\u003e,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard'],\n","resume_from_checkpoint=None,\n","run_name=translation-hi-hg_finetune,\n","save_on_each_node=False,\n","save_steps=500,\n","save_strategy=epoch,\n","save_total_limit=1,\n","seed=42,\n","sharded_ddp=[],\n","skip_memory_metrics=True,\n","sortish_sampler=False,\n","tf32=None,\n","torchdynamo=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","warmup_ratio=0.0,\n","warmup_steps=2500,\n","weight_decay=0.0,\n","xpu_backend=None,\n",")\n","07/30/2022 12:03:07 - WARNING - datasets.builder - Using custom data configuration default-e2b4f847be942fab\n","07/30/2022 12:03:07 - DEBUG - datasets.utils.filelock - Attempting to acquire lock 140680497134352 on /root/.cache/huggingface/datasets/_root_.cache_huggingface_datasets_json_default-e2b4f847be942fab_0.0.0_c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426.lock\n","07/30/2022 12:03:07 - DEBUG - datasets.utils.filelock - Lock 140680497134352 acquired on /root/.cache/huggingface/datasets/_root_.cache_huggingface_datasets_json_default-e2b4f847be942fab_0.0.0_c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426.lock\n","07/30/2022 12:03:07 - DEBUG - datasets.utils.filelock - Attempting to release lock 140680497134352 on /root/.cache/huggingface/datasets/_root_.cache_huggingface_datasets_json_default-e2b4f847be942fab_0.0.0_c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426.lock\n","07/30/2022 12:03:07 - DEBUG - datasets.utils.filelock - Lock 140680497134352 released on /root/.cache/huggingface/datasets/_root_.cache_huggingface_datasets_json_default-e2b4f847be942fab_0.0.0_c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426.lock\n","07/30/2022 12:03:07 - DEBUG - datasets.utils.filelock - Attempting to acquire lock 140680497134352 on /root/.cache/huggingface/datasets/_root_.cache_huggingface_datasets_json_default-e2b4f847be942fab_0.0.0_c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426.lock\n","07/30/2022 12:03:07 - DEBUG - datasets.utils.filelock - Lock 140680497134352 acquired on /root/.cache/huggingface/datasets/_root_.cache_huggingface_datasets_json_default-e2b4f847be942fab_0.0.0_c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426.lock\n","07/30/2022 12:03:07 - INFO - datasets.builder - Generating dataset json (/root/.cache/huggingface/datasets/json/default-e2b4f847be942fab/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426)\n","Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-e2b4f847be942fab/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426...\n","100% 2/2 [00:00\u003c00:00, 3255.18it/s]\n","07/30/2022 12:03:07 - INFO - datasets.utils.download_manager - Downloading took 0.0 min\n","07/30/2022 12:03:09 - INFO - datasets.utils.download_manager - Checksum Computation took 0.0 min\n","100% 2/2 [00:00\u003c00:00, 116.11it/s]\n","07/30/2022 12:03:09 - INFO - datasets.utils.info_utils - Unable to verify checksums.\n","07/30/2022 12:03:09 - INFO - datasets.builder - Generating split train\n","07/30/2022 12:03:09 - DEBUG - datasets.arrow_writer - Done writing 27999 examples in 23016315 bytes /root/.cache/huggingface/datasets/json/default-e2b4f847be942fab/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426.incomplete/json-train.arrow.\n","07/30/2022 12:03:09 - INFO - datasets.builder - Generating split validation\n","07/30/2022 12:03:09 - DEBUG - datasets.arrow_writer - Done writing 786 examples in 238911 bytes /root/.cache/huggingface/datasets/json/default-e2b4f847be942fab/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426.incomplete/json-validation.arrow.\n","07/30/2022 12:03:09 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n","07/30/2022 12:03:09 - DEBUG - datasets.utils.filelock - Attempting to acquire lock 140680498868368 on /root/.cache/huggingface/datasets/_root_.cache_huggingface_datasets_json_default-e2b4f847be942fab_0.0.0_c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426.incomplete.lock\n","07/30/2022 12:03:09 - DEBUG - datasets.utils.filelock - Lock 140680498868368 acquired on /root/.cache/huggingface/datasets/_root_.cache_huggingface_datasets_json_default-e2b4f847be942fab_0.0.0_c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426.incomplete.lock\n","07/30/2022 12:03:09 - DEBUG - datasets.utils.filelock - Attempting to release lock 140680498868368 on /root/.cache/huggingface/datasets/_root_.cache_huggingface_datasets_json_default-e2b4f847be942fab_0.0.0_c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426.incomplete.lock\n","07/30/2022 12:03:09 - DEBUG - datasets.utils.filelock - Lock 140680498868368 released on /root/.cache/huggingface/datasets/_root_.cache_huggingface_datasets_json_default-e2b4f847be942fab_0.0.0_c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426.incomplete.lock\n","Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-e2b4f847be942fab/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426. Subsequent calls will reuse this data.\n","07/30/2022 12:03:09 - DEBUG - datasets.utils.filelock - Attempting to release lock 140680497134352 on /root/.cache/huggingface/datasets/_root_.cache_huggingface_datasets_json_default-e2b4f847be942fab_0.0.0_c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426.lock\n","07/30/2022 12:03:09 - DEBUG - datasets.utils.filelock - Lock 140680497134352 released on /root/.cache/huggingface/datasets/_root_.cache_huggingface_datasets_json_default-e2b4f847be942fab_0.0.0_c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426.lock\n","07/30/2022 12:03:09 - DEBUG - datasets.builder - Constructing Dataset for split train, validation, from /root/.cache/huggingface/datasets/json/default-e2b4f847be942fab/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426\n","100% 2/2 [00:00\u003c00:00, 975.31it/s]\n","[INFO|hub.py:600] 2022-07-30 12:03:09,811 \u003e\u003e https://huggingface.co/google/mt5-xxl/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpg4gxbbt1\n","Downloading config.json: 100% 627/627 [00:00\u003c00:00, 439kB/s]\n","[INFO|hub.py:613] 2022-07-30 12:03:10,184 \u003e\u003e storing https://huggingface.co/google/mt5-xxl/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/9cec02711162f4c7d6b950771377ff7fc578b31e0e693da034de082b27fa0063.e52af75fc3110577d1a42cd1d6ade4fc692e8d42ffa3d82152504ad6b2be6ffd\n","[INFO|hub.py:621] 2022-07-30 12:03:10,185 \u003e\u003e creating metadata file for /root/.cache/huggingface/transformers/9cec02711162f4c7d6b950771377ff7fc578b31e0e693da034de082b27fa0063.e52af75fc3110577d1a42cd1d6ade4fc692e8d42ffa3d82152504ad6b2be6ffd\n","[INFO|configuration_utils.py:674] 2022-07-30 12:03:10,185 \u003e\u003e loading configuration file https://huggingface.co/google/mt5-xxl/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/9cec02711162f4c7d6b950771377ff7fc578b31e0e693da034de082b27fa0063.e52af75fc3110577d1a42cd1d6ade4fc692e8d42ffa3d82152504ad6b2be6ffd\n","[INFO|configuration_utils.py:723] 2022-07-30 12:03:10,187 \u003e\u003e Model config MT5Config {\n","  \"_name_or_path\": \"google/mt5-xxl\",\n","  \"architectures\": [\n","    \"T5ForConditionalGeneration\"\n","  ],\n","  \"d_ff\": 10240,\n","  \"d_kv\": 64,\n","  \"d_model\": 4096,\n","  \"decoder_start_token_id\": 0,\n","  \"dense_act_fn\": \"gelu_new\",\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"feed_forward_proj\": \"gated-gelu\",\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"is_gated_act\": true,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"mt5\",\n","  \"num_decoder_layers\": 24,\n","  \"num_heads\": 64,\n","  \"num_layers\": 24,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_max_distance\": 128,\n","  \"relative_attention_num_buckets\": 32,\n","  \"tie_word_embeddings\": false,\n","  \"tokenizer_class\": \"T5Tokenizer\",\n","  \"transformers_version\": \"4.21.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 250112\n","}\n","\n","[INFO|hub.py:600] 2022-07-30 12:03:10,555 \u003e\u003e https://huggingface.co/google/mt5-xxl/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpwh677q_8\n","Downloading tokenizer_config.json: 100% 376/376 [00:00\u003c00:00, 371kB/s]\n","[INFO|hub.py:613] 2022-07-30 12:03:10,918 \u003e\u003e storing https://huggingface.co/google/mt5-xxl/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/f48e72e226676d2b33f3a4d9c749d3ae3ac5eb75bb50464c3c494185bc38c512.28bbf90ae7962b1b7211c0ce8b2006f968c82439ec9c47e0847ba63642f9435a\n","[INFO|hub.py:621] 2022-07-30 12:03:10,918 \u003e\u003e creating metadata file for /root/.cache/huggingface/transformers/f48e72e226676d2b33f3a4d9c749d3ae3ac5eb75bb50464c3c494185bc38c512.28bbf90ae7962b1b7211c0ce8b2006f968c82439ec9c47e0847ba63642f9435a\n","[INFO|configuration_utils.py:674] 2022-07-30 12:03:11,282 \u003e\u003e loading configuration file https://huggingface.co/google/mt5-xxl/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/9cec02711162f4c7d6b950771377ff7fc578b31e0e693da034de082b27fa0063.e52af75fc3110577d1a42cd1d6ade4fc692e8d42ffa3d82152504ad6b2be6ffd\n","[INFO|configuration_utils.py:723] 2022-07-30 12:03:11,283 \u003e\u003e Model config MT5Config {\n","  \"_name_or_path\": \"google/mt5-xxl\",\n","  \"architectures\": [\n","    \"T5ForConditionalGeneration\"\n","  ],\n","  \"d_ff\": 10240,\n","  \"d_kv\": 64,\n","  \"d_model\": 4096,\n","  \"decoder_start_token_id\": 0,\n","  \"dense_act_fn\": \"gelu_new\",\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"feed_forward_proj\": \"gated-gelu\",\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"is_gated_act\": true,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"mt5\",\n","  \"num_decoder_layers\": 24,\n","  \"num_heads\": 64,\n","  \"num_layers\": 24,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_max_distance\": 128,\n","  \"relative_attention_num_buckets\": 32,\n","  \"tie_word_embeddings\": false,\n","  \"tokenizer_class\": \"T5Tokenizer\",\n","  \"transformers_version\": \"4.21.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 250112\n","}\n","\n","[INFO|hub.py:600] 2022-07-30 12:03:12,058 \u003e\u003e https://huggingface.co/google/mt5-xxl/resolve/main/spiece.model not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpm9hx4lcc\n","Downloading spiece.model: 100% 4.11M/4.11M [00:00\u003c00:00, 6.16MB/s]\n","[INFO|hub.py:613] 2022-07-30 12:03:13,315 \u003e\u003e storing https://huggingface.co/google/mt5-xxl/resolve/main/spiece.model in cache at /root/.cache/huggingface/transformers/fc052c498688513ed6478626d77922bcd670e43077ca0f2071c8ef85a01b15e1.84ea7af2df68dc8db434d3160aab65cce8ac63ce5b6f7743f8c9a4a14b4f77e2\n","[INFO|hub.py:621] 2022-07-30 12:03:13,315 \u003e\u003e creating metadata file for /root/.cache/huggingface/transformers/fc052c498688513ed6478626d77922bcd670e43077ca0f2071c8ef85a01b15e1.84ea7af2df68dc8db434d3160aab65cce8ac63ce5b6f7743f8c9a4a14b4f77e2\n","[DEBUG|tokenization_utils_base.py:1775] 2022-07-30 12:03:13,681 \u003e\u003e google/mt5-xxl does not contain a file named https://huggingface.co/google/mt5-xxl/resolve/main/tokenizer.json.\n","[DEBUG|tokenization_utils_base.py:1775] 2022-07-30 12:03:14,052 \u003e\u003e google/mt5-xxl does not contain a file named https://huggingface.co/google/mt5-xxl/resolve/main/added_tokens.json.\n","[INFO|hub.py:600] 2022-07-30 12:03:14,444 \u003e\u003e https://huggingface.co/google/mt5-xxl/resolve/main/special_tokens_map.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp5xgj5ec0\n","Downloading special_tokens_map.json: 100% 65.0/65.0 [00:00\u003c00:00, 55.5kB/s]\n","[INFO|hub.py:613] 2022-07-30 12:03:14,812 \u003e\u003e storing https://huggingface.co/google/mt5-xxl/resolve/main/special_tokens_map.json in cache at /root/.cache/huggingface/transformers/c7146e960d10c95cdbc96b381ba233ab07093ca494812331edae089b2ba19fd6.294ebaa4cd17bb284635004c92d2c4d522ec488c828dcce0c2471b6f28e3fe82\n","[INFO|hub.py:621] 2022-07-30 12:03:14,813 \u003e\u003e creating metadata file for /root/.cache/huggingface/transformers/c7146e960d10c95cdbc96b381ba233ab07093ca494812331edae089b2ba19fd6.294ebaa4cd17bb284635004c92d2c4d522ec488c828dcce0c2471b6f28e3fe82\n","[INFO|tokenization_utils_base.py:1803] 2022-07-30 12:03:15,181 \u003e\u003e loading file https://huggingface.co/google/mt5-xxl/resolve/main/spiece.model from cache at /root/.cache/huggingface/transformers/fc052c498688513ed6478626d77922bcd670e43077ca0f2071c8ef85a01b15e1.84ea7af2df68dc8db434d3160aab65cce8ac63ce5b6f7743f8c9a4a14b4f77e2\n","[INFO|tokenization_utils_base.py:1803] 2022-07-30 12:03:15,182 \u003e\u003e loading file https://huggingface.co/google/mt5-xxl/resolve/main/tokenizer.json from cache at None\n","[INFO|tokenization_utils_base.py:1803] 2022-07-30 12:03:15,182 \u003e\u003e loading file https://huggingface.co/google/mt5-xxl/resolve/main/added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:1803] 2022-07-30 12:03:15,182 \u003e\u003e loading file https://huggingface.co/google/mt5-xxl/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/c7146e960d10c95cdbc96b381ba233ab07093ca494812331edae089b2ba19fd6.294ebaa4cd17bb284635004c92d2c4d522ec488c828dcce0c2471b6f28e3fe82\n","[INFO|tokenization_utils_base.py:1803] 2022-07-30 12:03:15,182 \u003e\u003e loading file https://huggingface.co/google/mt5-xxl/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/f48e72e226676d2b33f3a4d9c749d3ae3ac5eb75bb50464c3c494185bc38c512.28bbf90ae7962b1b7211c0ce8b2006f968c82439ec9c47e0847ba63642f9435a\n","[INFO|configuration_utils.py:674] 2022-07-30 12:03:15,550 \u003e\u003e loading configuration file https://huggingface.co/google/mt5-xxl/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/9cec02711162f4c7d6b950771377ff7fc578b31e0e693da034de082b27fa0063.e52af75fc3110577d1a42cd1d6ade4fc692e8d42ffa3d82152504ad6b2be6ffd\n","[INFO|configuration_utils.py:723] 2022-07-30 12:03:15,551 \u003e\u003e Model config MT5Config {\n","  \"_name_or_path\": \"google/mt5-xxl\",\n","  \"architectures\": [\n","    \"T5ForConditionalGeneration\"\n","  ],\n","  \"d_ff\": 10240,\n","  \"d_kv\": 64,\n","  \"d_model\": 4096,\n","  \"decoder_start_token_id\": 0,\n","  \"dense_act_fn\": \"gelu_new\",\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"feed_forward_proj\": \"gated-gelu\",\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"is_gated_act\": true,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"mt5\",\n","  \"num_decoder_layers\": 24,\n","  \"num_heads\": 64,\n","  \"num_layers\": 24,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_max_distance\": 128,\n","  \"relative_attention_num_buckets\": 32,\n","  \"tie_word_embeddings\": false,\n","  \"tokenizer_class\": \"T5Tokenizer\",\n","  \"transformers_version\": \"4.21.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 250112\n","}\n","\n","[INFO|configuration_utils.py:674] 2022-07-30 12:03:16,365 \u003e\u003e loading configuration file https://huggingface.co/google/mt5-xxl/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/9cec02711162f4c7d6b950771377ff7fc578b31e0e693da034de082b27fa0063.e52af75fc3110577d1a42cd1d6ade4fc692e8d42ffa3d82152504ad6b2be6ffd\n","[INFO|configuration_utils.py:723] 2022-07-30 12:03:16,366 \u003e\u003e Model config MT5Config {\n","  \"_name_or_path\": \"google/mt5-xxl\",\n","  \"architectures\": [\n","    \"T5ForConditionalGeneration\"\n","  ],\n","  \"d_ff\": 10240,\n","  \"d_kv\": 64,\n","  \"d_model\": 4096,\n","  \"decoder_start_token_id\": 0,\n","  \"dense_act_fn\": \"gelu_new\",\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"feed_forward_proj\": \"gated-gelu\",\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"is_gated_act\": true,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"mt5\",\n","  \"num_decoder_layers\": 24,\n","  \"num_heads\": 64,\n","  \"num_layers\": 24,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_max_distance\": 128,\n","  \"relative_attention_num_buckets\": 32,\n","  \"tie_word_embeddings\": false,\n","  \"tokenizer_class\": \"T5Tokenizer\",\n","  \"transformers_version\": \"4.21.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 250112\n","}\n","\n","/usr/local/lib/python3.7/dist-packages/transformers/convert_slow_tokenizer.py:435: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  \"The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option\"\n","[INFO|hub.py:600] 2022-07-30 12:03:17,377 \u003e\u003e https://huggingface.co/google/mt5-xxl/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp23eit_1z\n","Downloading pytorch_model.bin:   4% 1.77G/48.1G [01:09\u003c24:00, 34.6MB/s]Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/urllib3/response.py\", line 362, in _error_catcher\n","    yield\n","  File \"/usr/local/lib/python3.7/dist-packages/urllib3/response.py\", line 444, in read\n","    data = self._fp.read(amt)\n","  File \"/usr/lib/python3.7/http/client.py\", line 465, in read\n","    n = self.readinto(b)\n","  File \"/usr/lib/python3.7/http/client.py\", line 502, in readinto\n","    if len(b) \u003e self.length:\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"mt5-simplification/finetune.py\", line 617, in \u003cmodule\u003e\n","    main()\n","  File \"mt5-simplification/finetune.py\", line 346, in main\n","    use_auth_token=True if model_args.use_auth_token else None,\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/auto/auto_factory.py\", line 446, in from_pretrained\n","    return model_class.from_pretrained(pretrained_model_name_or_path, *model_args, config=config, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\", line 1941, in from_pretrained\n","    user_agent=user_agent,\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/utils/hub.py\", line 292, in cached_path\n","    local_files_only=local_files_only,\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/utils/hub.py\", line 610, in get_from_cache\n","    file_name=file_name,\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/utils/hub.py\", line 453, in http_get\n","    for chunk in r.iter_content(chunk_size=1024):\n","  File \"/usr/local/lib/python3.7/dist-packages/requests/models.py\", line 751, in generate\n","    for chunk in self.raw.stream(chunk_size, decode_content=True):\n","  File \"/usr/local/lib/python3.7/dist-packages/urllib3/response.py\", line 496, in stream\n","    data = self.read(amt=amt, decode_content=decode_content)\n","  File \"/usr/local/lib/python3.7/dist-packages/urllib3/response.py\", line 461, in read\n","    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n","  File \"/usr/lib/python3.7/contextlib.py\", line 130, in __exit__\n","    self.gen.throw(type, value, traceback)\n","  File \"/usr/local/lib/python3.7/dist-packages/urllib3/response.py\", line 399, in _error_catcher\n","    self._connection.close()\n","  File \"/usr/lib/python3.7/http/client.py\", line 961, in close\n","    sock.close()   # close it manually... there may be other refs\n","  File \"/usr/lib/python3.7/socket.py\", line 420, in close\n","    self._real_close()\n","  File \"/usr/lib/python3.7/ssl.py\", line 1129, in _real_close\n","    self._sslobj = None\n","KeyboardInterrupt\n","Downloading pytorch_model.bin:   4% 1.77G/48.1G [01:09\u003c30:31, 27.2MB/s]\n"]}],"source":["# weight_decay# #for simplification\n","model=\"google/mt5-xxl\"\n","!python mt5-simplification/finetune.py \\\n","    --model_name_or_path $model \\\n","    --do_train \\\n","    --do_eval \\\n","    --adafactor \\\n","    --source_lang hi \\\n","    --target_lang en \\\n","    --source_prefix \"hi-en: \" \\\n","    --train_file hi-hg/train.json \\\n","    --validation_file hi-hg/valid.json \\\n","    --output_dir mt5-hi-hg \\\n","    --per_device_train_batch_size=4 \\\n","    --per_device_eval_batch_size=4 \\\n","    --save_total_limit=1 \\\n","    --adam_epsilon=1e-6 \\\n","    --learning_rate=3e-5 \\\n","    --save_strategy=epoch \\\n","    --max_steps=10000 \\\n","    --warmup_steps=2500 \\\n","    --overwrite_output_dir \\\n","    --log_level debug \\\n","    --output_dir translation-hi-hg_finetune \\\n","    --predict_with_generate "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":175056,"status":"ok","timestamp":1659198747059,"user":{"displayName":"Girish Budhrani","userId":"13607137338318636456"},"user_tz":-330},"id":"497252a3","outputId":"62d5aa3d-b676-4141-bead-65ef2d96e5c0"},"outputs":[{"name":"stdout","output_type":"stream","text":["INFO:root:Starting predictions for hi-hg task.\n","INFO:root:358 Source Sentences found.\n","INFO:root:Predicting 1000 Sentences.\n","INFO:root:Loading translation-hg-hi model.\n","INFO:root:Starting predictions on cuda.\n","INFO:root:Model and Tokenizer loaded successfully. Starting predictions.\n","INFO:root:Max length set to 700.\n","INFO:root:Verbosity set to h.\n","INFO:root:Temperature set to 1.000000.\n","INFO:root:Top k set to 50.\n","INFO:root:Top p set to 0.950000.\n","INFO:root:Repeptition penalty set to 1.500000.\n","INFO:root:Number of beams is set to 1.000000.\n","INFO:root:Number of beams is set to 0.000000.\n","INFO:root:Length penalty set to 0.000000\n","INFO:root:Num return sequences set to 1.000000\n","INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n"]}],"source":["model_path=\"translation-hg-hi\"\n","task=\"hi-hg\"\n","# model_path=\"google/mt5-base\"\n","!python mt5-simplification/prediction.py \\\n","    hi-hg/test.hi \\\n","    --model-path $model_path \\\n","    --max_length 700 \\\n","    --output hypo.sys \\\n","    --count 1000 \\\n","    --verbosity h \\\n","    --task $task \\\n","    --topk 50 \\\n","    --topp 0.95 \\\n","    --rep_pen 1.5"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":552,"status":"ok","timestamp":1659198813392,"user":{"displayName":"Girish Budhrani","userId":"13607137338318636456"},"user_tz":-330},"id":"90da25af","outputId":"8611562d-a0f1-4388-8168-24fc113fbca4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reply kaise aap in website ko secure roop se delete kar sakte hain? \n","Aap aapko apne liye ek prayas ki jaate. \n","Aap ka naam aapko ek baat hai. \n","Aap aaj army unke question dekhkar hihne lage. \n","Aap service sabhi (phool) hai aur (par kar ladha diya jane wale) books mukhetra me milne. \n","Aap baat ho ki me to bahut khud ko '' vahi '' ke mujhe (aaj se) chalta hai (sabhi aap dono ko \"vhi\" ke madhyay (Ahad se) chhata gaya hai toh vah pahle hi koi nahi sakte (bhari kya khada) aur baare ko jab chahiye (burne ka nahin sakta hai. \n","Aur yeh pahle lau-laa tatha ek rup ki sthit ke saath jaata hai. \n","Isliye iske pramukh jindiyon ko ham purani sakte hain jisse vah sabse nahi rahta hai. \n","Aap aapko ek liye sabhi-vidyi prayog ko badhti dene. \n","yah aapko chahta hai ki aap isliye sakte hain ki vah kya hota hai. \n"]}],"source":["!head hypo.sys"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":816,"status":"ok","timestamp":1658586337785,"user":{"displayName":"Girish Budhrani","userId":"13607137338318636456"},"user_tz":-330},"id":"itVIuoVvaFYz","outputId":"098c8b7f-888c-42f0-93ae-b3a7f93e7d4d"},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n"," \"name\": \"BLEU\",\n"," \"score\": 4.5,\n"," \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.1.0\",\n"," \"verbose_score\": \"31.2/9.8/3.2/1.0 (BP = 0.816 ratio = 0.831 hyp_len = 5856 ref_len = 7049)\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"no\",\n"," \"tok\": \"13a\",\n"," \"smooth\": \"exp\",\n"," \"version\": \"2.1.0\"\n","}\n","\u001b[0m"]}],"source":["!sacrebleu hi-hg/test.en \u003c hypo.sys"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11166,"status":"ok","timestamp":1658586348949,"user":{"displayName":"Girish Budhrani","userId":"13607137338318636456"},"user_tz":-330},"id":"_C_hvBg8Pkb2","outputId":"c26243e1-16e4-430a-ad85-072109decb02"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting rouge\n","  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rouge) (1.15.0)\n","Installing collected packages: rouge\n","Successfully installed rouge-1.0.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting jiwer\n","  Downloading jiwer-2.3.0-py3-none-any.whl (15 kB)\n","Collecting python-Levenshtein==0.12.2\n","  Downloading python-Levenshtein-0.12.2.tar.gz (50 kB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50 kB 6.0 MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein==0.12.2-\u003ejiwer) (57.4.0)\n","Building wheels for collected packages: python-Levenshtein\n","  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp37-cp37m-linux_x86_64.whl size=149875 sha256=061a171ea7695c70e2b7c3c8a1ad0f5110aad91921598ce52d23c6470dad787a\n","  Stored in directory: /root/.cache/pip/wheels/05/5f/ca/7c4367734892581bb5ff896f15027a932c551080b2abd3e00d\n","Successfully built python-Levenshtein\n","Installing collected packages: python-Levenshtein, jiwer\n","Successfully installed jiwer-2.3.0 python-Levenshtein-0.12.2\n"]}],"source":["!pip install rouge\n","!pip install jiwer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lJATAG1yNDZb"},"outputs":[],"source":["from rouge import Rouge\n","from jiwer import wer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UUPSZFczNFhg"},"outputs":[],"source":["with open('hi-hg/test.en') as f:\n","    orig = f.readlines()\n","with open('hypo.sys') as f:\n","    result = f.readlines()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1658586348950,"user":{"displayName":"Girish Budhrani","userId":"13607137338318636456"},"user_tz":-330},"id":"LfjFg8eANHIn","outputId":"c61c7a08-15cc-460b-8e5a-0f958e40eb92"},"outputs":[{"data":{"text/plain":["{'rouge-1': {'f': 0.2696578854681659,\n","  'p': 0.26544248795197967,\n","  'r': 0.2884708202908629},\n"," 'rouge-2': {'f': 0.08140914640469989,\n","  'p': 0.07974459190059426,\n","  'r': 0.0885682087517222},\n"," 'rouge-l': {'f': 0.26199281115045703,\n","  'p': 0.25795497236387266,\n","  'r': 0.2800075656914783}}"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["rouge = Rouge()\n","rouge.get_scores(orig, result, avg=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1658586348950,"user":{"displayName":"Girish Budhrani","userId":"13607137338318636456"},"user_tz":-330},"id":"eTIFF4r7NIoh","outputId":"cc8dcd4c-9f19-43f5-ea69-847f5ed8a8d0"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/jiwer/measures.py:182: UserWarning: keyword argument `standardize` is deprecated. Please use `truth_transform=jiwer.transformations.wer_standardize` and `hypothesis_transform=jiwer.transformations.wer_standardize` instead\n","  \"keyword argument `standardize` is deprecated. \"\n"]},{"data":{"text/plain":["0.8653307794312657"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["wer(orig, result, standardize=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":871},"executionInfo":{"elapsed":6757,"status":"ok","timestamp":1658953622081,"user":{"displayName":"Girish Budhrani","userId":"13607137338318636456"},"user_tz":-330},"id":"oP4_fmAvUL0Q","outputId":"9741c879-7e4f-46c7-b834-e35b7ec15179"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers[torch]==4.3\n","  Downloading transformers-4.3.0-py3-none-any.whl (1.8 MB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.8 MB 5.1 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 880 kB 46.2 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers[torch]==4.3) (4.64.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers[torch]==4.3) (3.7.1)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers[torch]==4.3) (1.21.6)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers[torch]==4.3) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[torch]==4.3) (2022.6.2)\n","Collecting tokenizers\u003c0.11,\u003e=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.3 MB 52.8 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers[torch]==4.3) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers[torch]==4.3) (4.12.0)\n","Requirement already satisfied: torch\u003e=1.0 in /usr/local/lib/python3.7/dist-packages (from transformers[torch]==4.3) (1.12.0+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch\u003e=1.0-\u003etransformers[torch]==4.3) (4.1.1)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003etransformers[torch]==4.3) (3.8.1)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-\u003etransformers[torch]==4.3) (3.0.9)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers[torch]==4.3) (3.0.4)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers[torch]==4.3) (2.10)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers[torch]==4.3) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers[torch]==4.3) (1.24.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers[torch]==4.3) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers[torch]==4.3) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers[torch]==4.3) (1.1.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=3b686e3e3873742633e8f2a784bf8ad396705bc23ea5fa1603d38c3fe0b535de\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, transformers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.12.1\n","    Uninstalling tokenizers-0.12.1:\n","      Successfully uninstalled tokenizers-0.12.1\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.21.0\n","    Uninstalling transformers-4.21.0:\n","      Successfully uninstalled transformers-4.21.0\n","Successfully installed sacremoses-0.0.53 tokenizers-0.10.3 transformers-4.3.0\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["transformers"]}}},"metadata":{},"output_type":"display_data"}],"source":["# !pip install transformers\n","!pip install transformers[torch]==4.3"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":374},"executionInfo":{"elapsed":443,"status":"error","timestamp":1658953631384,"user":{"displayName":"Girish Budhrani","userId":"13607137338318636456"},"user_tz":-330},"id":"V6AYD-vdUInK","outputId":"b9488781-677a-4e94-9be1-18f821bff6c4"},"outputs":[{"ename":"ImportError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-11-bb5c6ef98f37\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMT5Model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT5Tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# from transformers import T5Model, T5Tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMT5Model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"google/mt5-base\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT5Tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"google/mt5-base\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'MT5Model' from 'transformers' (unknown location)","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}],"source":["from transformers import MT5Model, T5Tokenizer\n","# from transformers import T5Model, T5Tokenizer\n","\n","model = MT5Model.from_pretrained(\"google/mt5-base\")\n","tokenizer = T5Tokenizer.from_pretrained(\"google/mt5-base\")\n","article = \"UN Offizier sagt, dass weiter verhandelt werden muss in Syrien.\"\n","summary = \"Weiter Verhandlung in Syrien.\"\n","inputs = tokenizer(article, return_tensors=\"pt\")\n","with tokenizer.as_target_tokenizer():\n","    labels = tokenizer(summary, return_tensors=\"pt\")\n","\n","outputs = model(input_ids=inputs[\"input_ids\"], decoder_input_ids=labels[\"input_ids\"])\n","hidden_states = outputs.last_hidden_state"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aZ9S9ZT6UJDG"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"machine_shape":"hm","name":"Mt5.ipynb","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":10041.01092,"end_time":"2021-12-18T18:49:04.480127","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2021-12-18T16:01:43.469207","version":"2.3.3"}},"nbformat":4,"nbformat_minor":5}